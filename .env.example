# Resume Parser - Production Configuration Examples

# ============================================================================
# DEVELOPMENT - Basic Testing
# ============================================================================
# Simple setup for local testing without LLM
# GROK_API_KEY=<not-required>
# MASTER_KEY=<not-required>
# ADMIN_TOKEN=<not-required>
# python app.py


# ============================================================================
# STAGING - LLM Extraction with Runtime Key
# ============================================================================
# Development environment with LLM using runtime API key
# GROK_API_KEY=sk-xxxxxxxxxxxxxx
# GROK_API_URL=https://api.openai.com/v1/chat/completions
# GROK_MODEL=gpt-4o-mini
# USE_LLM_MODE=human
# PARSE_WORKERS=4
# PARSE_MAX_UPLOADS=500
# PARSE_MAX_FILE_MB=10
# python app.py


# ============================================================================
# PRODUCTION - Secure with Server-Side Key Storage
# ============================================================================
# High-security production setup with encrypted key storage

# 1. Generate master key:
#    python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
#
# 2. Set environment variables:
MASTER_KEY=<YOUR-GENERATED-FERNET-KEY-HERE>
ADMIN_TOKEN=<YOUR-SECRET-ADMIN-TOKEN>
DEFAULT_THEME=dark
PARSE_WORKERS=8
PARSE_LLM_CONCURRENCY=3
PARSE_MAX_UPLOADS=500
PARSE_MAX_FILE_MB=10
STORE_ORIGINALS=1

# 3. Start server:
#    python app.py
#
# 4. Store API key on server (one time):
#    curl -X POST http://localhost:5050/admin/set_api_key \
#      -H "X-ADMIN-TOKEN: <YOUR-SECRET-ADMIN-TOKEN>" \
#      -H "Content-Type: application/json" \
#      -d '{"api_key":"sk-..."}'
#
# 5. Verify key storage:
#    curl -X GET "http://localhost:5050/admin/has_api_key?admin_token=<YOUR-SECRET-ADMIN-TOKEN>"
#
# 6. Deploy behind reverse proxy (nginx/Apache) with HTTPS and rate limiting


# ============================================================================
# PRODUCTION - High-Performance Cluster
# ============================================================================
# Multiple workers with increased concurrency for high throughput

MASTER_KEY=<YOUR-GENERATED-FERNET-KEY-HERE>
ADMIN_TOKEN=<YOUR-SECRET-ADMIN-TOKEN>
DEFAULT_THEME=light
PARSE_WORKERS=16
PARSE_LLM_CONCURRENCY=6
PARSE_BATCH_SIZE=100
PARSE_MAX_UPLOADS=1000
PARSE_MAX_FILE_MB=20
STORE_ORIGINALS=0
GROK_MODEL=gpt-4

# Deploy with:
# - Load balancer (distribute across multiple instances)
# - Redis cache for distributed state
# - External secrets manager (AWS Secrets Manager, Azure Key Vault)


# ============================================================================
# DEPLOYMENT CHECKLIST
# ============================================================================
# ✓ Use HTTPS (nginx/Apache reverse proxy)
# ✓ Enable CORS headers if needed
# ✓ Set strong ADMIN_TOKEN (min 32 chars)
# ✓ Configure rate limiting on reverse proxy
# ✓ Setup monitoring/logging
# ✓ Regular backups of MASTER_KEY
# ✓ Use external secrets manager instead of .env files
# ✓ Test with load testing before production
# ✓ Set up automated security scanning
# ✓ Monitor API quota usage
